from pydantic import BaseModel, Field, field_validator
from typing import Literal, Dict, Any, Optional, List, Union
from enum import Enum
import json
from .content import VisionMultimodalContentItem

# =============================================================================
# ENUMS AND CONSTANTS
# =============================================================================

class ModelType(str, Enum):
    """Available model types"""
    GLM_4_5 = "glm-4.5"
    GLM_4_5V = "glm-4.5v"
    GPT_5 = "gpt-5"

class MessageRole(str, Enum):
    """Message roles"""
    USER = "user"
    SYSTEM = "system"
    ASSISTANT = "assistant"
    TOOL = "tool"

class ToolType(str, Enum):
    """Tool types"""
    FUNCTION = "function"

class ResponseFormatType(str, Enum):
    """Response format types"""
    TEXT = "text"
    JSON_OBJECT = "json_object"

class ThinkingType(str, Enum):
    """Thinking/reasoning types"""
    ENABLED = "enabled"
    DISABLED = "disabled"

# =============================================================================
# TOOL MODELS
# =============================================================================

class FunctionParameters(BaseModel):
    """Function parameters defined using JSON Schema"""
    type: str = "object"
    properties: Dict[str, Any] = Field(default_factory=dict)
    required: List[str] = Field(default_factory=list)
    
    class Config:
        extra = "allow"

class FunctionObject(BaseModel):
    """Function definition"""
    name: str = Field(..., min_length=1, max_length=64, pattern=r"^[a-zA-Z0-9_-]+$", description="The name of the function to be called")
    description: str = Field(..., description="A description of what the function does")
    parameters: FunctionParameters = Field(..., description="Parameters defined using JSON Schema")

class FunctionTool(BaseModel):
    """Function tool schema"""
    type: Literal[ToolType.FUNCTION] = ToolType.FUNCTION
    function: FunctionObject

# Union type for all tools (just function tools for now)
Tool = FunctionTool

# =============================================================================
# MESSAGE MODELS
# =============================================================================

class ChatThinking(BaseModel):
    """Chain of thought configuration"""
    type: ThinkingType = Field(default=ThinkingType.ENABLED, description="Whether to enable the chain of thought")

class ResponseFormat(BaseModel):
    """Response format specification"""
    type: ResponseFormatType = Field(default=ResponseFormatType.TEXT, description="Output format type")

class ToolCallFunction(BaseModel):
    """Function call information in tool calls"""
    name: str = Field(..., description="Function name")
    arguments: str = Field(..., description="Function parameters, JSON format string")
    
    @field_validator('arguments', mode='before')
    @classmethod
    def validate_arguments(cls, v):
        """Ensure arguments is a valid JSON string"""
        if isinstance(v, str):
            try:
                json.loads(v)
                return v
            except json.JSONDecodeError:
                raise ValueError("arguments must be a valid JSON string")
        elif isinstance(v, dict):
            return json.dumps(v)
        else:
            raise ValueError("arguments must be a string or dict")

class ToolCall(BaseModel):
    """Tool call in assistant message"""
    id: str = Field(..., description="Tool call ID")
    type: ToolType = Field(..., description="Tool type")
    function: Optional[ToolCallFunction] = Field(None, description="Function call information, not empty when type is function")
    
    def parse_arguments(self) -> Dict[str, Any]:
        """Parse the function arguments from JSON string to dict"""
        if self.function and self.function.arguments:
            try:
                return json.loads(self.function.arguments)
            except json.JSONDecodeError:
                return {}
        return {}

class UserMessage(BaseModel):
    """User message"""
    role: Literal[MessageRole.USER] = MessageRole.USER
    content: Union[str, List[VisionMultimodalContentItem]] = Field(..., description="Message content - text string or multimodal content array")

class SystemMessage(BaseModel):
    """System message"""
    role: Literal[MessageRole.SYSTEM] = MessageRole.SYSTEM
    content: str = Field(..., description="Message text content")

class AssistantMessage(BaseModel):
    """Assistant message"""
    role: Literal[MessageRole.ASSISTANT] = MessageRole.ASSISTANT
    content: Optional[str] = Field(None, description="Text message content")
    tool_calls: Optional[List[ToolCall]] = Field(None, description="Tool call messages generated by the model")

class ToolMessage(BaseModel):
    """Tool message"""
    role: Literal[MessageRole.TOOL] = MessageRole.TOOL
    content: Union[str, List[VisionMultimodalContentItem]] = Field(..., description="Message content - text string or multimodal content array")
    tool_call_id: str = Field(..., description="Indicates the tool call ID corresponding to this message")

# Union type for all message types
Message = Union[UserMessage, SystemMessage, AssistantMessage, ToolMessage]

# =============================================================================
# REQUEST MODELS
# =============================================================================

# Text-only user message (for text models)
class TextOnlyUserMessage(BaseModel):
    """User message with text content only"""
    role: Literal[MessageRole.USER] = MessageRole.USER
    content: str = Field(..., description="Text message content only")

# Text-only message types (for text models)
TextMessage = Union[TextOnlyUserMessage, SystemMessage, AssistantMessage, ToolMessage]

class ChatCompletionRequestBase(BaseModel):
    """Base chat completion request with common fields"""
    request_id: Optional[str] = Field(None, description="User-provided unique request ID")
    do_sample: bool = Field(default=True, description="Whether to enable sampling strategy")
    stream: bool = Field(default=False, description="Whether to stream the response")
    thinking: Optional[ChatThinking] = Field(None, description="Chain of thought configuration")
    tools: Optional[List[Tool]] = Field(None, max_items=128, description="List of tools the model may call")
    user_id: Optional[str] = Field(None, min_length=6, max_length=128, description="Unique ID for the end user")
    stop: Optional[List[str]] = Field(None, max_items=1, description="Stop word list")

class ChatCompletionTextRequest(ChatCompletionRequestBase):
    """Chat completion request for text models - text content only"""
    model: Literal[ModelType.GLM_4_5] = Field(default=ModelType.GLM_4_5, description="Text model")
    messages: List[TextMessage] = Field(..., min_items=1, description="Text-only conversation messages")
    temperature: float = Field(default=0.6, ge=0.0, le=1.0, description="Sampling temperature")
    top_p: float = Field(default=0.95, ge=0.0, le=1.0, description="Top-p sampling parameter")
    max_tokens: Optional[int] = Field(default=None, ge=1, le=98304, description="Maximum number of tokens for model output")
    response_format: Optional[ResponseFormat] = Field(None, description="Response format specification")

class ChatCompletionVisionRequest(ChatCompletionRequestBase):
    """Chat completion request for vision models - supports multimodal content"""
    model: Literal[ModelType.GLM_4_5V] = Field(default=ModelType.GLM_4_5V, description="Vision model")
    messages: List[Message] = Field(..., min_items=1, description="Multimodal conversation messages")
    temperature: float = Field(default=0.8, ge=0.0, le=1.0, description="Sampling temperature")
    top_p: float = Field(default=0.6, ge=0.0, le=1.0, description="Top-p sampling parameter")
    max_tokens: Optional[int] = Field(default=None, ge=1, le=16384, description="Maximum number of tokens for model output")

# Main request type
ChatCompletionRequest = Union[ChatCompletionTextRequest, ChatCompletionVisionRequest]

# =============================================================================
# RESPONSE MODELS
# =============================================================================

class PromptTokensDetails(BaseModel):
    """Prompt tokens details"""
    cached_tokens: int = Field(default=0, description="Number of tokens served from cache")

class Usage(BaseModel):
    """Token usage statistics"""
    prompt_tokens: int = Field(..., description="Number of tokens in user input")
    completion_tokens: int = Field(..., description="Number of output tokens")
    prompt_tokens_details: Optional[PromptTokensDetails] = Field(None, description="Detailed prompt token information")
    total_tokens: int = Field(..., description="Total number of tokens")

class ResponseMessage(BaseModel):
    """Response message"""
    role: str = Field(default="assistant", description="Current conversation role")
    content: Optional[str] = Field(None, description="Current conversation content")
    reasoning_content: Optional[str] = Field(None, description="Reasoning content, supports by GLM-4.5 series")
    tool_calls: Optional[List[ToolCall]] = Field(None, description="Function names and parameters generated by the model")

class Choice(BaseModel):
    """Response choice"""
    index: int = Field(..., description="Result index")
    message: ResponseMessage = Field(..., description="Response message")
    finish_reason: Optional[str] = Field(None, description="Reason for model inference termination")

class ChatCompletionResponse(BaseModel):
    """Chat completion response"""
    id: str = Field(..., description="Task ID")
    request_id: str = Field(..., description="Request ID")
    created: int = Field(..., description="Request creation time, Unix timestamp in seconds")
    model: str = Field(..., description="Model name")
    choices: List[Choice] = Field(..., description="List of model responses")
    usage: Optional[Usage] = Field(None, description="Token usage statistics")

class Error(BaseModel):
    """Error response"""
    code: int = Field(..., description="Error code")
    message: str = Field(..., description="Error message")

# =============================================================================
# LEGACY COMPATIBILITY MODELS (for existing code)
# =============================================================================

# Keep some existing models for backward compatibility
class InputMessage(BaseModel):
    """Legacy input message model for compatibility"""
    role: str
    content: str

class OpenAIResponseBase(BaseModel):
    """Base model containing all the OpenAI response metadata fields"""
    id: str
    request_id: str
    created: int = Field(description="Request creation time, Unix timestamp in seconds")
    model: str = Field(description="Model name used for the request")

class OpenAIResponse(OpenAIResponseBase):
    """Legacy OpenAI response model for compatibility"""
    choices: Optional[List[Choice]] = None
    usage: Optional[Usage] = None
    object: Optional[str] = None


# =============================================================================
# STREAMING RESPONSE MODELS
# =============================================================================

class StreamEventType(str, Enum):
    """Types of streaming events"""
    START = "start"
    LLM_CALL = "llm_call"
    THINKING = "thinking"
    TOOL_EXECUTION = "tool_execution"
    MESSAGE = "message"
    PRODUCT = "product"
    PRODUCT_GRID = "product_grid"
    CONTENT_DISPLAY = "content_display"  # New: Direct content streaming
    CONTENT_UPDATE = "content_update"    # New: Content updates
    COMPLETE = "complete"
    ERROR = "error"

class LLMCallStatus(str, Enum):
    """Status of LLM calls"""
    STARTED = "started"
    CONTINUING = "continuing"
    COMPLETED = "completed"

class ToolExecutionStatus(str, Enum):
    """Status of tool execution"""
    STARTED = "started"
    PROGRESS = "progress"
    COMPLETED = "completed"
    ERROR = "error"

class StreamEvent(BaseModel):
    """Base streaming event"""
    type: StreamEventType = Field(..., description="Type of the streaming event")
    timestamp: Optional[str] = Field(None, description="Event timestamp")

class LLMCallEvent(StreamEvent):
    """LLM call event"""
    type: Literal[StreamEventType.LLM_CALL] = StreamEventType.LLM_CALL
    status: LLMCallStatus = Field(..., description="Status of the LLM call")
    message: Optional[str] = Field(None, description="Optional message about the call")

class ThinkingEvent(StreamEvent):
    """Thinking/reasoning event"""
    type: Literal[StreamEventType.THINKING] = StreamEventType.THINKING
    content: str = Field(..., description="Thinking content from the LLM")

class ToolExecutionEvent(StreamEvent):
    """Tool execution event"""
    type: Literal[StreamEventType.TOOL_EXECUTION] = StreamEventType.TOOL_EXECUTION
    tool_name: str = Field(..., description="Name of the tool being executed")
    status: ToolExecutionStatus = Field(..., description="Status of the tool execution")
    tool_call_id: str = Field(..., description="ID of the tool call")
    message: Optional[str] = Field(None, description="Optional message about the execution")
    progress: Optional[Dict[str, Any]] = Field(None, description="Optional progress information")
    result: Optional[str] = Field(None, description="Optional result data")
    error: Optional[str] = Field(None, description="Optional error message")

class MessageEvent(StreamEvent):
    """Message event for final responses"""
    type: Literal[StreamEventType.MESSAGE] = StreamEventType.MESSAGE
    content: str = Field(..., description="Message content")
    final: bool = Field(default=False, description="Whether this is the final message")

class ProductGridEvent(StreamEvent):
    """Product grid event for streaming products"""
    type: Literal[StreamEventType.PRODUCT_GRID] = StreamEventType.PRODUCT_GRID
    title: str = Field(..., description="Title for the product grid")
    products: List[Dict[str, Any]] = Field(..., description="List of products to display")
    count: int = Field(..., description="Number of products")

class ProductEvent(StreamEvent):
    """Individual product event for streaming single products"""
    type: Literal[StreamEventType.PRODUCT] = StreamEventType.PRODUCT
    product: Dict[str, Any] = Field(..., description="Product data")

class ContentDisplayEvent(StreamEvent):
    """Direct content display event for flexible UI updates"""
    type: Literal[StreamEventType.CONTENT_DISPLAY] = StreamEventType.CONTENT_DISPLAY
    content_type: str = Field(..., description="Type of content (products, comparison, summary, etc.)")
    data: Dict[str, Any] = Field(..., description="Content data")
    title: Optional[str] = Field(None, description="Optional title for the content")
    metadata: Optional[Dict[str, Any]] = Field(None, description="Optional metadata")

class ContentUpdateEvent(StreamEvent):
    """Content update event for modifying existing content"""
    type: Literal[StreamEventType.CONTENT_UPDATE] = StreamEventType.CONTENT_UPDATE
    update_type: str = Field(..., description="Type of update (add, remove, modify, filter)")
    target_id: str = Field(..., description="ID of content to update")
    data: Dict[str, Any] = Field(..., description="Update data")
    metadata: Optional[Dict[str, Any]] = Field(None, description="Optional metadata")

class CompleteEvent(StreamEvent):
    """Completion event"""
    type: Literal[StreamEventType.COMPLETE] = StreamEventType.COMPLETE
    response: ChatCompletionResponse = Field(..., description="Final LLM response")

class ErrorEvent(StreamEvent):
    """Error event"""
    type: Literal[StreamEventType.ERROR] = StreamEventType.ERROR
    error: str = Field(..., description="Error message")

# Union type for all streaming events
StreamingEvent = Union[
    LLMCallEvent,
    ThinkingEvent, 
    ToolExecutionEvent,
    MessageEvent,
    ProductGridEvent,
    ProductEvent,
    ContentDisplayEvent,
    ContentUpdateEvent,
    CompleteEvent,
    ErrorEvent
]

# Legacy compatibility - keeping the old ToolExecutionResponse for backward compatibility
class ToolExecutionResponse(BaseModel):
    """Tool execution response for streaming (legacy)"""
    tool_name: str = Field(..., description="Name of the tool being executed")
    status: str = Field(..., description="Status of the tool execution (started, completed, error, etc.)")
    message: Optional[str] = Field(None, description="Optional message about the execution")
    progress: Optional[Dict[str, Any]] = Field(None, description="Optional progress information")
    result: Optional[str] = Field(None, description="Optional result data")
    error: Optional[str] = Field(None, description="Optional error message")
    